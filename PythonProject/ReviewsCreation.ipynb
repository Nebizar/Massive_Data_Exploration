{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\apasi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aed64a5d3a5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import string\n",
    "import nltk \n",
    "import re\n",
    "import joblib\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/reviews_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET\n",
      "Shape of training data: (555791, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET\")\n",
    "print(f'Shape of training data: {dataset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A35C43YE9HU9CN</td>\n",
       "      <td>B0064X7B4A</td>\n",
       "      <td>Joan Miller</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I have decided not to play this game.  I can't...</td>\n",
       "      <td>Friends</td>\n",
       "      <td>1396396800</td>\n",
       "      <td>04 2, 2014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AHFS8CGWWXB5B</td>\n",
       "      <td>B00H1P4V3E</td>\n",
       "      <td>WASH ST. GAMER</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>The Amazon Appstore free app of the day for Ju...</td>\n",
       "      <td>Amazon Makes This \"Longest Spring Ever\" for Fi...</td>\n",
       "      <td>1402272000</td>\n",
       "      <td>06 9, 2014</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A3EW8OTQ90NVHM</td>\n",
       "      <td>B00CLVW82O</td>\n",
       "      <td>Kindle Customer</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>this game was so mush fun I wish I could play ...</td>\n",
       "      <td>best</td>\n",
       "      <td>1368921600</td>\n",
       "      <td>05 19, 2013</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AJ3GHFJY1IUTD</td>\n",
       "      <td>B007T9WVKM</td>\n",
       "      <td>BrawlMaster4</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>Its pretty fun and very good looking,  but you...</td>\n",
       "      <td>Fun Game</td>\n",
       "      <td>1350172800</td>\n",
       "      <td>10 14, 2012</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A3JJGBS4EL603S</td>\n",
       "      <td>B00J206J5E</td>\n",
       "      <td>K. Wilson \"thesupe\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>good graphics; immersive storyline; hard to st...</td>\n",
       "      <td>great game!</td>\n",
       "      <td>1396915200</td>\n",
       "      <td>04 8, 2014</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin         reviewerName helpful  \\\n",
       "0  A35C43YE9HU9CN  B0064X7B4A          Joan Miller  [0, 0]   \n",
       "1   AHFS8CGWWXB5B  B00H1P4V3E       WASH ST. GAMER  [3, 4]   \n",
       "2  A3EW8OTQ90NVHM  B00CLVW82O      Kindle Customer  [0, 4]   \n",
       "3   AJ3GHFJY1IUTD  B007T9WVKM         BrawlMaster4  [0, 2]   \n",
       "4  A3JJGBS4EL603S  B00J206J5E  K. Wilson \"thesupe\"  [0, 0]   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I have decided not to play this game.  I can't...   \n",
       "1  The Amazon Appstore free app of the day for Ju...   \n",
       "2  this game was so mush fun I wish I could play ...   \n",
       "3  Its pretty fun and very good looking,  but you...   \n",
       "4  good graphics; immersive storyline; hard to st...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                            Friends      1396396800   \n",
       "1  Amazon Makes This \"Longest Spring Ever\" for Fi...      1402272000   \n",
       "2                                               best      1368921600   \n",
       "3                                           Fun Game      1350172800   \n",
       "4                                        great game!      1396915200   \n",
       "\n",
       "    reviewTime  score  \n",
       "0   04 2, 2014    1.0  \n",
       "1   06 9, 2014    2.0  \n",
       "2  05 19, 2013    5.0  \n",
       "3  10 14, 2012    5.0  \n",
       "4   04 8, 2014    5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555791 entries, 0 to 555790\n",
      "Data columns (total 9 columns):\n",
      "reviewerID        555791 non-null object\n",
      "asin              555791 non-null object\n",
      "reviewerName      555777 non-null object\n",
      "helpful           555791 non-null object\n",
      "reviewText        555783 non-null object\n",
      "summary           555767 non-null object\n",
      "unixReviewTime    555791 non-null int64\n",
      "reviewTime        555791 non-null object\n",
      "score             555791 non-null float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_missing = dataset[['reviewText', 'summary']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText     8\n",
       "summary       24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 555745 entries, 0 to 555790\n",
      "Data columns (total 3 columns):\n",
      "reviewText    555745 non-null object\n",
      "summary       555745 non-null object\n",
      "score         555745 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['reviewText', 'summary', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 416808 entries, 14240 to 318243\n",
      "Data columns (total 3 columns):\n",
      "reviewText    416808 non-null object\n",
      "summary       416808 non-null object\n",
      "score         416808 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 138937 entries, 48959 to 112352\n",
      "Data columns (total 3 columns):\n",
      "reviewText    138937 non-null object\n",
      "summary       138937 non-null object\n",
      "score         138937 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_prepare_data(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    newdf = df.copy()\n",
    "    # prepare text, delete punctuation and stop words\n",
    "    newdf['tokenized'] = newdf.reviewText.apply(lambda x : word_tokenize(x))\n",
    "    newdf['tokenized'] = newdf['tokenized'].apply(lambda x : np.array([word for word in x if word.isalnum()]) )\n",
    "    newdf['tokenized'] = newdf['tokenized'].apply(lambda x : np.array([word for word in x if word not in STOP_WORDS]) )\n",
    "    # lemmatizing and stemming\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    newdf['tokenized'] = newdf['tokenized'].apply(lambda x : np.array([wnl.lemmatize(ps.stem(i.lower())) for i in x]) )\n",
    "    #count final words number\n",
    "    newdf['count_words'] = newdf['tokenized'].apply(lambda x : len(x))\n",
    "    # delete recurring words - to check\n",
    "    newdf['unique_words'] = newdf['tokenized'].apply(lambda x : np.unique(x))\n",
    "    # create text from words \n",
    "    newdf['new_text'] = newdf['unique_words'].apply(lambda x : ' '.join(x))\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = convert_and_prepare_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 416808 entries, 14240 to 318243\n",
      "Data columns (total 7 columns):\n",
      "reviewText      416808 non-null object\n",
      "summary         416808 non-null object\n",
      "score           416808 non-null float64\n",
      "tokenized       416808 non-null object\n",
      "count_words     416808 non-null int64\n",
      "unique_words    416808 non-null object\n",
      "new_text        416808 non-null object\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 25.4+ MB\n"
     ]
    }
   ],
   "source": [
    "trainDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = trainDf.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    211343\n",
       "4.0     87353\n",
       "3.0     47961\n",
       "1.0     44906\n",
       "2.0     25245\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.to_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "trainCV = countVectorizer.fit_transform(trainDf['new_text'])\n",
    "\n",
    "tfVectorizer = TfidfVectorizer(min_df = 2, max_df = 0.5, ngram_range= (1,2))\n",
    "trainTF = tfVectorizer.fit_transform(trainDf['new_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(model, parameters, X_train, y_train):\n",
    "    gs = GridSearchCV(\n",
    "        model,\n",
    "        parameters,\n",
    "        cv = 4,  #cross-validation splitting\n",
    "        n_jobs = -1, #using all processors, \n",
    "        return_train_score = True\n",
    "    )\n",
    "    best_model = gs.fit(X_train, y_train)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={'Logistic Regression': LogisticRegression(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'K-NN': KNeighborsClassifier(),\n",
    "        'Random Forest': RandomForestClassifier()}\n",
    "parameters={\n",
    "      'Logistic Regression':{\n",
    "                              \"C\":np.logspace(-3,3,7), \n",
    "                              \"penalty\":[\"l1\",\"l2\"]},\n",
    "            \n",
    "\n",
    "        'Decision Tree':{\n",
    "             'criterion' :['gini', 'entropy'], \n",
    "             'splitter':['best', 'random'], \n",
    "              'max_depth' : [4,5,6,7,8],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']},\n",
    "\n",
    "        'K-NN':  { \n",
    "              'n_neighbors': [3,5,7,9,11 ,10,12,13], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan']},\n",
    "            \n",
    "        'Random Forest': { \n",
    "                        'n_estimators': [100, 200, 350, 500],\n",
    "                        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                        'max_depth' : [4,5,6,7,8],\n",
    "                        'criterion' :['gini', 'entropy']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(models,parameters,  X_trainCV, X_trainTF, y_train):\n",
    "    best_models_cv = {}\n",
    "    best_models_tf = {}\n",
    "    for name, model in models.items():\n",
    "        print('##### ' + name + ' #####')\n",
    "        best_models_cv[name] = get_best_model(model,parameters[name], X_trainCV,y_train)\n",
    "        best_models_tf[name] = get_best_model(model,parameters[name],X_trainTF ,y_train)\n",
    "\n",
    "    return best_models_cv, best_models_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(models):\n",
    "    for name, model in models.items():\n",
    "        filename = f'models/{name}_tf.sav'\n",
    "        joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Logistic Regression #####\n"
     ]
    }
   ],
   "source": [
    "best_models_cv, best_models_tf = get_best_models(models,parameters, trainCV, trainTF, trainDf.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
